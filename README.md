# AskAnything
项目源自在某大型互联网公司从0到1搭建知识问答系统的经验。包括：FAQ、文档问答和任务型对话三类任务。（已脱敏）
## 业务数据特点
由于企业内容数据的私有化属性，只从宏观角度介绍数据概况和处理时遇到的困难
## 产品规划
根据数据特点，和业务需要实现的目标，规划FAQ、文档问答、任务型对话和RPA的建设<br>
### 任务
根据业务目标，调研实现不同任务需要的功能
![1721490831951](https://github.com/user-attachments/assets/7f4d6796-39de-4205-9cf3-aaf619bcf352)


### 分类规划
* FAQ<br>
由于
* 文档问答
* 任务型对话
* RPA规划
## 技术选型
### 客服框架调研
* 调研传统智能客服框架和基于大模型的智能客服框架的区别：1.[RASA](https://github.com/RasaHQ/rasa)2.[Qanything](https://github.com/netease-youdao/qanything) 3.[MaxKB](https://github.com/1panel-dev/MaxKB) 4.[智谱Ai](https://zhuanlan.zhihu.com/p/704828374?utm_psn=1797042432065552385)

|   |  原理（流程图）  |  支持任务  |  功能点  |  优点  |  缺点  |
| --- | --- | --- | --- | --- | --- |
|  RASA  |  Rasa基于意图的问答 ![rasa-流程图.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYDQEpgdO8j9/img/24130173-e09b-4319-9d0d-5725da474ab9.png) Rasa基于LLM和RAG的意图分类 ![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYDQEpgdO8j9/img/7678f410-c217-4129-afac-2e4cd68b494d.png)  |  FAQ问答  |  1.意图识别<br>2.实体抽取<br> 3.上下文记忆<br> 4.自定义动作  |1.支持纯本地部署<br>2.具有模块化框架<br>3.可以外接知识图谱<br>4.可自定义回复动作       |  功能缺点：1.不能进行文档问答<br>模型缺点：1.组件的ML和DL模型组件过时<br> 2.每次更新示例时需要重新训练       |
|  [QAnything](https://qanything.ai/docs/introduce)  |  基于RAG的两阶段检索机制，结合信息检索和文本生成![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYDQEpgdO8j9/img/3312fb3c-66cd-4a09-89bf-1b6873e351d1.png) 参数设置：<br>1.检索：不设置阈值，返回TOP K.<br> 2.重排：阈值0.35       |  1.文档问答<br> 2.FAQ问答  |  1.文档解析<br> 2.混合检索（BM25+向量检索）<br> 3.联网检索<br> 4.业务场景定制<br> 5.对话日志  |  1.支持纯本地部署<br> 2.无文档数量上限<br> 3.问答准确率高<br> 4.支持多语言       |  数据侧：<br>1.处理非结构化文档存在困难<br> 2.从图片、pdf等非文本格式提取信息<br> 3.文档数量增加，检索速度和生成效率      模型侧：<br>1.大模型计算资源消耗大<br> 2.对特定领域数据的依赖等问题       |
|  [MaxKB](https://maxkb.cn/docs/system_arch/)  |  ![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYDQEpgdO8j9/img/b396642d-0f50-4cca-afae-c3b818282e2b.png)  |   |  1.  知识库：<br>1.多格式文档导入、自动分段向量化；命中检测<br> 2.  应用： Agent工作流；嵌入第三方；对话日志；访问限制；用量统计<br>3.系统管理       |  1.开箱即用<br>2.多格式多类型文档，在线/离线，文本自动拆分、向量化、RAG<br>3.无缝嵌入:可以快速嵌入到第三方系统<br>4.灵活编排:工作流配置<br>5.模型中立:可自行接入其他大模型  |  模型：召回相似度Top N问题       |
|  智谱AI  |  ![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/Mp7ldVyDdEEvqBQN/img/193b8094-eea9-413c-8a32-faf9c5ed03aa.jpg) 参数设置：<br>1.重排：文本得分+向量得分，权重分别为0.3和0.7       |   |  1.query改写<br>2.路由<br>3.多路召回<br>4.文本检索+向量检索（ES混合检索）  |   |   |

### 大模型技术框架调研
* 调研[LangChain](https://github.com/langchain-ai/langchain)、[LlamaIndex](https://github.com/run-llama/llama_index)等技术框架

|   |  功能模块  |  具体功能  |  应用场景  |  缺点  |
| --- | --- | --- | --- | --- |
|  Langchain （适合复杂的对话系统，如聊天机器人，智能助手）  |  模板<br>Agent<br>Chain<br>记忆<br>提示工程<br>模型接口<br>文档QA  | 1.从文档生成QA对<br>2.多轮对话记忆<br>3.根据输入内容路由到指定的链       |  1.更适合构建面向企业的、可以产生收入的产品。这些产品需要支持多种模型接口、提供丰富的功能和优化的性能。\n 2.适用于需要构建更加复杂的对话系统的场景，如聊天机器人、智能助手等。       | 1.抽象程度较高，可能增加代码复杂性和学习成本。<br>2.在某些情况下可能不够灵活，限制了底层代码的编写和调试。       |
|  LlamaIndex  |  数据连接<br>索引构建<br>查询接口  |   |  1.更适合用于构建RAG系统，提升大型语言模型在处理长文本或大量数据时的查询效率。<br>2.提供简化的数据索引和查询能力。<br>3.适用于需要处理大量数据、对查询性能有较高要求的场景，如搜索引擎、推荐系统等。       |  1.功能相对单一，主要侧重于检索和索引，不如LangChain功能丰富。<br>2.对模型接口的支持较少，可能限制某些特定需求的实现。       |

### 大模型技术调研
* 调研RAG、Function Calling、RAGFlow等技术的原理，以及在搜索时的具体应用场景和作用<br>

|   |  原理  |  核心组件  |  适用场景  |  优点  |  缺点  |
| --- | --- | --- | --- | --- | --- |
|  RAG  |  外部知识库中检索相关信息来增强语言模型的回答能力  |  信息检索<br>文本生成  |  需要处理大量数据和复杂查询的场景，如知识问答、文档检索等  | 1.解决大语言模型的知识过期和细分领域的幻觉问题。<br>2.增强模型生成能力，提供更准确、更丰富的回答       |  1.需要预先构建和维护知识库，增加系统复杂性<br>2.对于实时性和非公开数据的处理能力有限       |
|  RAGFlow  |  ![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/Mp7ldVyDdEEvqBQN/img/d5cc8ac6-1b7f-48ca-baeb-682f30f831a4.jpg)  |  多路召回  | null  | null  | null  |
|  Function Calling  |  将用户的自然语言请求转换为可执行的函数调用，并生成符合预定义函数签名的结构化输出，如JSON对象  |1.系统接收用户问题并检查是否有可用函数<br> 2.系统生成工具调用请求（ToolCall），应用程序执行请求的函数，并返回结果。<br> 3.系统返回函数的响应（ToolCallResponse），生成最终的用户响应       |  需要实时数据或特定服务的场景，如天气预报、股票信息查询等  |  1.灵活的方式来扩展语言模型的能力，允许模型调用外部API或服务<br> 2.可以获取实时数据，解决大模型知识滞后的问题       | 1.开发者定义和维护外部函数，增加开发和维护的复杂性<br>  2.函数调用的准确性和可靠性依赖于外部服务的稳定性和响应时间       |

### 搜索技术调研
|  类型  |  算法  |  适用场景  |  优点  |  缺点  |
| --- | --- | --- | --- | --- |
|  关键词  |  tf-idf  |  *   文本分类      *   信息检索      *   特征提取       |  *   简单直观，易于实现。      *   能够反映词语在文档中的重要性。      *   通过IDF部分减少了常见词的影响。       |  *   不考虑词语的上下文信息。      *   对于短文本，TF可能不够稳定。      *   无法捕捉到词语之间的语义关系。       |
|  静态词向量  |  Word2Vec  |  *   语义分析      *   文本相似度计算      *   词嵌入表示      但在处理多义词和罕见词时效果较差。  |  *   能够捕捉词语之间的语义关系。      *   生成的词向量可以用于多种下游任务。      *   训练速度快，模型参数相对固定。       |  *   训练完成后，词向量是静态的，无法适应新数据。      *   无法很好地处理长距离依赖问题。      *   在处理词语的多义性和上下文关系上存在局限。       |
|  动态词向量  |  Bert  |  *   需要丰富上下文信息的任务语言理解任务，如如自然语言推理、问答系统或机器翻译等。      *   作为预训练模型，微调用于特定任务。       |  *   双向上下文理解，能够捕捉更丰富的语义信息。      *   预训练模型可以在多种任务上进行微调，表现出色。      *   通过注意力机制，能够更好地处理长距离依赖问题。       |  *   模型参数多，计算量大，训练和推理速度慢。      *   对于小数据集可能过拟合。       |
|

## MVP产品框架
### 系统架构

关键词搜索和语义搜索的区别，哪个场景应该用什么，具体的搜索场景和实现
![image](https://github.com/user-attachments/assets/7685e72b-a10a-4e81-a255-32397938239e)




### FAQ框架

![image.png](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/MAeqxYDQEpgdO8j9/img/54dbd950-9c5a-43ee-8ee6-78cc00569481.png)


### 用户流程
![image](https://github.com/user-attachments/assets/558c8520-576b-4ce2-977c-cedfbbb17b57)


### 产品功能
为保证系统快速上线，功能能够满足用户的基本需求，同时保证上线后的问答效果，提出MVP方案。功能设计需要保证后续迭代的可以实现正常的功能叠加，减少二次开发过程<br>
![image](https://github.com/user-attachments/assets/10ba8c6e-1934-4d1e-a110-ef66bff09d98)




## 问答测试
### 评价指标
**离线自动指标**<br>
1.  召回（主要通过检索过程提高）：
    1.  $Recall = TP/(TP+FN)$  
    2.  $模型根据用户query正确预测到标准问的数量/所有有标准问的用户query$       
2.  精确度：
    1.  $Accuracy = (TP+TN)/(TP+FN+FP+TN)$ 
    2.  $预测结果和实际结果一致的数量/用户query总数$
3.  准确度（主要通过重排序过程提高）：
    1.  $Precision = TP/(TP+FP)$
    2.  $预测标准问和实际标准问一致的数量/模型根据用户query预测到的标准问的数量$

**离线人工指标**<br>
1.  内部技术专家后台提问测试问题匹配准确性和问题解决率<br>

**上线后业务指标**<br>
1.  问题解决率
2.  转工单数量

### 离线自动指标测试方案
**测试方法**<br>
1.  关键词搜索：TF-IDF
2.  静态词向量：Word2Vec
3.  动态词向量：BGE系列

**提示词引导LLM生成测试集**<br>
1.  测试集形式：三元组（query，是否存在标准问，标准问）
2.  测试集生成
    1.  标准问选择要求
        1.  代表性：用户历史问题中总结出5类常见查询类型，评估模型对不同类型问题的理解能力
        2.  复杂性：用来评估模型对不同复杂度问题的理解能力
        4.  多样性：覆盖尽可能多的类型
        5.  明确性：问题清晰无歧义，
        6.  独立性：每个标准问都是独立的，不与其他问题相似
    3.  用户query生成要求
        1. 正样本
            1.  与标准问完全一致
            2.  语义等价但表述不同的：考虑同义词、近义词的使用，以及句子结构的变化。
            3.  包含额外信息的标准问：在标准问的基础上增加时间、地点、数量等细节信息。
            4.  使用自然语言变体：考虑口语化表达、缩写、俚语等，以模拟真实用户的语言习惯。
        2. 负样本
            1.  与标准问明显不相关的：主题差异，。。。。
            2.  与标准问表面相似实际不相关的（陷阱问题）：例如，“如何设置闹钟？”与“如何关闭闹钟？”虽然都涉及闹钟，但询问的目的完全不同。
            3.  包含误导性信息的query：引入与标准问无关或冲突的细节，测试模型的抗干扰能力
            4.  非常规语法结构：构造语法上正确但逻辑上与标准问不符的query，评估模型对异常句式的理解。

**测试过程**<br>
1.  使用测试集分别测试不同方法的匹配效果，记录匹配结果
    1. 准确率
    2. 召回率

**bad case识别与优化**<br>
**bad case1**<br>
1.  问题描述：现有知识组织形式无法完全统一
2.  问题本身所属类别：问题集合类，比如xxx常见问题
3.  溯源
4.  改进方案：多级搜索
5.  优化结果
   
**bad case2**<br>
1.  问题描述：词近意远
2.  问题本身所属类别：问题集合类，比如xxx常见问题；如何解决xx问题
3.  溯源
4.  改进方案：增加rerank
5.  优化结果
   
**bad case3**<br>
1.  问题描述：版本号相近
2.  问题本身所属类别：问题集合类，比如xxx版本信息表
3.  溯源
4.  改进方案：混合搜索
5.  优化结果

**示例代码**<br>

### 离线人工测试方案
## 未来规划
### 意图识别：
在实践中，我们意识到不同类型的问题在搜索过程中出现的异常情况是不同的，需要针对不同类型的问题设计精细化的策略，故此，我们将在下一步尝试使用llm进行意图识别，并根据识别到的结果采用rpa路由到不同的链路中
### query改写：
### 相似问：
我们将会在实践中进一步测试，添加相似问对准确率和召回率的提升效果，从而决定是否上线这一功能
